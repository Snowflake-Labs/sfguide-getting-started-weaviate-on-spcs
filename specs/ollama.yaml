spec:
  container:
  - name: ollama
    image: "<SNOWFLAKE_ORG>-<SNOWFLAKE_ACCOUNT>.registry.snowflakecomputing.com/weaviate_demo/public/weaviate_repo/ollama"
    env:
      LLM_MODEL: mistral
      ENABLE_CUDA: 1
      NVIDIA_VISIBLE_DEVICES : all
    resources:
      limits:
        memory: 192G
        nvidia.com/gpu: 4
      requests:
        memory: 188G
        nvidia.com/gpu: 4
  endpoint:
  - name: ollama 
    port: 11434

